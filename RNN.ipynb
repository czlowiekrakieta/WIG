{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import json\n",
    "import copy\n",
    "\n",
    "sc = \"/home/lukasz/Dokumenty/python gieldowy/WIG/\"\n",
    "srednie_branze = pd.read_csv(sc + \"srednie_branzowe.csv\")\n",
    "with open(\"wlasnosci.txt\", \"r\") as f:\n",
    "    wlasnosci = json.load(f)\n",
    "\n",
    "pliki = os.listdir(sc + \"spolki_do_branzy\")\n",
    "liczba_krokow = 6\n",
    "rozmiar_probki = 128\n",
    "rozmiar_wejscia = len(wlasnosci)\n",
    "ukryta_warstwa = 128\n",
    "\n",
    "val = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wszystkie_dane = []\n",
    "wszystkie_klasy = []\n",
    "\n",
    "for plik in pliki:\n",
    "    \n",
    "    df = pd.read_csv(sc + \"wszystko_3M/\" + plik).set_index(\"Unnamed: 0\")\n",
    "    kl = df[\"ZKlasy\"]\n",
    "    df = df[wlasnosci]\n",
    "    \n",
    "    df.fillna(0, inplace=True) #wypelnic srednia branzowa\n",
    "    \n",
    "    df = df.as_matrix()\n",
    "    \n",
    "    for i in range( df.shape[0] - liczba_krokow ):\n",
    "        wszystkie_dane.append( df[i:i+liczba_krokow, :] )\n",
    "        wszystkie_klasy.append( kl[i+liczba_krokow-1] )\n",
    "\n",
    "for i, rz in enumerate(wszystkie_klasy):\n",
    "    \n",
    "    if rz == 0:\n",
    "        wszystkie_klasy[i] = [0, 1]\n",
    "    else:\n",
    "        wszystkie_klasy[i] = [1, 0]\n",
    "\n",
    "wielkosc = len(wszystkie_dane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wszystkie_dane = np.asarray(wszystkie_dane)\n",
    "np.place( wszystkie_dane, np.isinf(wszystkie_dane), 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13978, 6, 159)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wszystkie_dane.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, liczba_krokow, rozmiar_wejscia])\n",
    "stan = tf.placeholder(\"float\", [None, 2*ukryta_warstwa])\n",
    "Y = tf.placeholder(\"float\", [None, 2])\n",
    "\n",
    "tempo_uczenia = 1e-3\n",
    "\n",
    "wagi = {\n",
    "    \"ukryte\": tf.Variable( tf.truncated_normal([rozmiar_wejscia, ukryta_warstwa])),\n",
    "    \"wyjscie\": tf.Variable( tf.truncated_normal([ukryta_warstwa, 2]))\n",
    "}\n",
    "\n",
    "przes = {\n",
    "    \"ukryte\": tf.Variable( tf.truncated_normal([ukryta_warstwa])),\n",
    "    \"wyjscie\": tf.Variable( tf.truncated_normal([2]))\n",
    "}\n",
    "\n",
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  \n",
    "    _X = tf.reshape(_X, [-1, rozmiar_wejscia]) \n",
    "    _X = tf.matmul(_X, _weights['ukryte']) + _biases['ukryte']\n",
    "    \n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(ukryta_warstwa, forget_bias=1.0)\n",
    "    _X = tf.split(0, liczba_krokow, _X)\n",
    "    \n",
    "    outputs, states = rnn.rnn(lstm_cell, _X, initial_state=_istate)\n",
    "    \n",
    "    \n",
    "    return tf.matmul(outputs[-1], _weights['wyjscie']) + _biases['wyjscie']\n",
    "\n",
    "\n",
    "pred = RNN(X, stan, wagi, przes)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, Y)) # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=tempo_uczenia).minimize(cost) # Adam Optimizer\n",
    "\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamy iterację nr: 32768 , dokładność: 0.492 , stratę 1.271 a dokladnosc testu: 0.600\n",
      "Mamy iterację nr: 65536 , dokładność: 0.570 , stratę 1.055 a dokladnosc testu: 0.609\n",
      "Mamy iterację nr: 98304 , dokładność: 0.641 , stratę 0.850 a dokladnosc testu: 0.605\n",
      "Mamy iterację nr: 131072 , dokładność: 0.500 , stratę 0.804 a dokladnosc testu: 0.621\n",
      "Mamy iterację nr: 163840 , dokładność: 0.594 , stratę 0.763 a dokladnosc testu: 0.600\n",
      "Mamy iterację nr: 196608 , dokładność: 0.602 , stratę 0.705 a dokladnosc testu: 0.607\n",
      "Mamy iterację nr: 229376 , dokładność: 0.594 , stratę 0.699 a dokladnosc testu: 0.617\n",
      "Mamy iterację nr: 262144 , dokładność: 0.570 , stratę 0.706 a dokladnosc testu: 0.623\n",
      "Mamy iterację nr: 294912 , dokładność: 0.609 , stratę 0.674 a dokladnosc testu: 0.621\n",
      "Mamy iterację nr: 327680 , dokładność: 0.625 , stratę 0.683 a dokladnosc testu: 0.623\n",
      "Mamy iterację nr: 360448 , dokładność: 0.672 , stratę 0.630 a dokladnosc testu: 0.617\n",
      "Mamy iterację nr: 393216 , dokładność: 0.633 , stratę 0.629 a dokladnosc testu: 0.561\n",
      "Mamy iterację nr: 425984 , dokładność: 0.602 , stratę 0.660 a dokladnosc testu: 0.611\n",
      "Mamy iterację nr: 458752 , dokładność: 0.570 , stratę 0.830 a dokladnosc testu: 0.625\n",
      "Mamy iterację nr: 491520 , dokładność: 0.664 , stratę 0.613 a dokladnosc testu: 0.621\n",
      "Mamy iterację nr: 524288 , dokładność: 0.586 , stratę 0.695 a dokladnosc testu: 0.615\n",
      "Mamy iterację nr: 557056 , dokładność: 0.555 , stratę 0.803 a dokladnosc testu: 0.523\n",
      "Mamy iterację nr: 589824 , dokładność: 0.594 , stratę 0.683 a dokladnosc testu: 0.617\n",
      "Mamy iterację nr: 622592 , dokładność: 0.602 , stratę 0.674 a dokladnosc testu: 0.623\n",
      "Mamy iterację nr: 655360 , dokładność: 0.656 , stratę 0.640 a dokladnosc testu: 0.621\n",
      "Mamy iterację nr: 688128 , dokładność: 0.609 , stratę 0.722 a dokladnosc testu: 0.627\n",
      "Mamy iterację nr: 720896 , dokładność: 0.633 , stratę 0.654 a dokladnosc testu: 0.627\n",
      "Mamy iterację nr: 753664 , dokładność: 0.594 , stratę 0.679 a dokladnosc testu: 0.623\n",
      "Mamy iterację nr: 786432 , dokładność: 0.578 , stratę 0.667 a dokladnosc testu: 0.621\n",
      "Mamy iterację nr: 819200 , dokładność: 0.594 , stratę 0.677 a dokladnosc testu: 0.625\n",
      "Mamy iterację nr: 851968 , dokładność: 0.633 , stratę 0.627 a dokladnosc testu: 0.623\n",
      "Mamy iterację nr: 884736 , dokładność: 0.555 , stratę 0.675 a dokladnosc testu: 0.625\n",
      "Mamy iterację nr: 917504 , dokładność: 0.617 , stratę 0.620 a dokladnosc testu: 0.627\n",
      "Mamy iterację nr: 950272 , dokładność: 0.664 , stratę 0.630 a dokladnosc testu: 0.625\n",
      "Mamy iterację nr: 983040 , dokładność: 0.555 , stratę 0.681 a dokladnosc testu: 0.621\n"
     ]
    }
   ],
   "source": [
    "dlugosc_treningu = int(1e6)\n",
    "wyswietlamy = pow(2,15)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "los = np.random.permutation( wszystkie_dane.shape[0] )\n",
    "\n",
    "val_X = np.asarray(wszystkie_dane)[los[:val], :, :]\n",
    "val_Y = np.asarray(wszystkie_klasy)[los[:val]]\n",
    "\n",
    "train_X = np.asarray(wszystkie_dane)[los[val:]]\n",
    "train_Y = np.asarray(wszystkie_klasy)[los[val:]]\n",
    "wielkosc -= val\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    \n",
    "    while step*rozmiar_probki < dlugosc_treningu:\n",
    "        start = step*rozmiar_probki % (wielkosc - rozmiar_probki)\n",
    "        step += 1\n",
    "        dane_X, dane_Y = train_X[start:start+rozmiar_probki], train_Y[start:start+rozmiar_probki]\n",
    "    \n",
    "        sess.run( optimizer, feed_dict = {X:dane_X, Y:dane_Y, stan: np.zeros((rozmiar_probki, 2*ukryta_warstwa))} )\n",
    "        \n",
    "        if step*rozmiar_probki % wyswietlamy == 0:\n",
    "            \n",
    "            acc = sess.run(accuracy, feed_dict={X: dane_X, Y: dane_Y,\n",
    "                                                stan: np.zeros((rozmiar_probki, 2*ukryta_warstwa))})\n",
    "            loss = sess.run(cost, feed_dict={X: dane_X, Y: dane_Y,\n",
    "                                             stan: np.zeros((rozmiar_probki, 2*ukryta_warstwa))})\n",
    "            \n",
    "            #t = sess.run( pred, feed_dict = {X: dane_X, \n",
    "            \n",
    "            a_V = 0\n",
    "            for i in range(4):\n",
    "                acc_val = sess.run( accuracy, feed_dict={X: val_X[i*128:(i+1)*128], Y: val_Y[i*128:(i+1)*128],\n",
    "                                                stan: np.zeros((rozmiar_probki, 2*ukryta_warstwa))})\n",
    "                a_V += acc_val\n",
    "                \n",
    "            a_V /= 4\n",
    "            \n",
    "            print( \"Mamy iterację nr: {0}\".format(step*rozmiar_probki), \", dokładność: {:.3f}\".format(acc), \\\n",
    "                  \", stratę {:.3f}\".format(loss), \"a dokladnosc testu: {:.3f}\".format(a_V))\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
